# Task 1: Music Recommendation System using Collaborative Filtering

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# 1. Sample simulated dataset (user_id, song_id, listen_count)
data = {
    'user_id': [1, 1, 1, 2, 2, 3, 3, 4, 5],
    'song_id': [101, 102, 103, 101, 104, 102, 105, 101, 103],
    'listen_count': [5, 3, 2, 4, 1, 2, 5, 3, 4]
}

df = pd.DataFrame(data)

# 2. Create user-song matrix
user_song_matrix = df.pivot_table(index='user_id', columns='song_id', values='listen_count', fill_value=0)

# 3. Calculate similarity between users
user_similarity = cosine_similarity(user_song_matrix)
user_similarity_df = pd.DataFrame(user_similarity, index=user_song_matrix.index, columns=user_song_matrix.index)

# 4. Recommend songs for a user (e.g., user_id = 1)
def recommend_songs(target_user_id, user_song_matrix, user_similarity_df, top_n=3):
    similar_users = user_similarity_df[target_user_id].sort_values(ascending=False)
    similar_users = similar_users.drop(target_user_id)

    recommendation_scores = user_song_matrix.T.dot(similar_users).div(similar_users.sum())
    user_songs = user_song_matrix.loc[target_user_id]
    recommended_songs = recommendation_scores[user_songs == 0].sort_values(ascending=False).head(top_n)

    return recommended_songs.index.tolist()

# Example: Recommend songs for user 1
recommended = recommend_songs(1, user_song_matrix, user_similarity_df)
print(f"Recommended songs for User 1: {recommended}")



# Task 2: Image Recognition - Complete Code

import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import matplotlib.pyplot as plt

# 1. Load and preprocess the dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# 2. Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

# 3. Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 4. Train the model
model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# 5. Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_acc}")